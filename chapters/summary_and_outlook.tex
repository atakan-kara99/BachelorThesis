\chapter{Summary and Outlook}

In this thesis, we conducted a comparison of manifold learning methods, including Multi-Dimensional Scaling (MDS), Locally Linear Embedding (LLE), and t-Distributed Stochastic Neighbor Embedding (t-SNE), across multiple datasets, namely the original 3D -Mammoth, a transformed version of it and the COIL-20 dataset. Our analysis focused on distance and neighborhood preservation, visualization quality, and clusterability on embeddings. Notably, MDS consistently demonstrated impressive performance in all of these evaluations despite having no parameter that can be set. Because of the minimal expense and the consistently good results, MDS is highly recommended to use. If the task is to get the best neighborhood preservation without considering the visualization quality we recommend using t-SNE with low parameter settings. The use of LLE is not recommended at all because one can achieve the same or better results with far less computationally intensive executions. If your goal is to get the best visualization it is besides MDS recommended to use t-SNE with as high parameter settings as possible without falling into the trap of the vicious unstable state.

The downside of the research we did in this work is that MDS and LLE are rather outdated. There are a lot of versions that extend these methods and methods that are up-to-date such as UMAP. It is also more meaningful to evaluate the performances of these methods on more real-world-oriented datasets because manifold learning methods do differ substantially in their behavior when deployed on these. \cite{Zubova18} We also found out that the evaluation criteria we chose to evaluate our experiments were not complete, meaning that we, for example, could not grasp the visualization quality of the low dimensional embeddings. The question that arises is if there is a complete list of evaluation criteria that can completely quantify the performance of an embedding. Another question could then be if and how these criteria relate to each other meaning if they are maybe mainly or partly proportional to each other. Furthermore, delving deeper into the intermediate steps of LLE and t-SNE, which are not provided by sklearn, can help identify when and why embeddings break. Understanding these breakpoints is crucial for improving the robustness of these methods. We chose to transform the 3D-Mammoth dataset in a way that datapoints are no longer connected anymore meaning that the manifold is non-continuous. These transformations can further be done by maybe capturing the Mammoth in motion so that it is no longer symmetric resulting in fewer linear relations, or straightening the body parts that are curved to investigate the impact of short-circuiting. Another weak point of our work is that we mainly focused on the best and worst performances of the methods. Investigating and analyzing results that had mediocre good results could reveal many more peculiarities of the manifold learning methods.

We, therefore, suggest further conducting more research with other manifold learning methods on other datasets with another, and maybe a complete, list of evaluation criteria. In conclusion, manifold learning remains a vibrant and evolving field with substantial potential for further innovations. Our research contributes to the ongoing discourse, providing a foundation for method selection and opening doors to future investigations. As the challenges posed by high-dimensional data continue to grow, the insights gained from this and future research will play a vital role in enhancing our understanding of manifold learning methods and in the following our ability to extract meaningful information from complex datasets, ultimately advancing various fields of science and technology.